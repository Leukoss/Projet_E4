{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Packages"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3dc24c927b60b438"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2                                # state of the art computer vision algorithms library\n",
    "import numpy as np                        # fundamental package for scientific computing\n",
    "import mediapipe as mp                    # pose estimation through mp\n",
    "import pyrealsense2 as rs                 # Intel RealSense cross-platform open-source API"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T20:08:52.177031800Z",
     "start_time": "2024-04-22T20:08:27.196354800Z"
    }
   },
   "id": "2a3a249c70ed29e5",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setup Camera"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d058f3db92b8463"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Initialize to retrieve the camera flow\n",
    "pipe = rs.pipeline()\n",
    "cfg = rs.config()\n",
    "\n",
    "# Define the format of both stream\n",
    "cfg.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "cfg.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "\n",
    "# Align both cameras\n",
    "align = rs.align(rs.stream.color)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T20:09:37.569517300Z",
     "start_time": "2024-04-22T20:09:37.409897Z"
    }
   },
   "id": "6cf21c2450db88d4",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setup Calibration Target"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abef65bbeb1bdae9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the parameters for cornerSubPix\n",
    "winSize = (5, 5)  # Size of the window for searching sub-pixel corner\n",
    "zeroZone = (-1, -1)  # No search zone restriction around the corner\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)  # Termination criteria\n",
    "\n",
    "# Define the size of our calibration target\n",
    "pattern_size = (7, 7)\n",
    "\n",
    "objp = np.zeros((1, pattern_size[0] * pattern_size[1], 3), np.float32)\n",
    "objp[0,:,:2] = np.mgrid[0:pattern_size[0], 0:pattern_size[1]].T.reshape(-1, 2)\n",
    "\n",
    "images = []\n",
    "images_corners = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T20:28:04.196065300Z",
     "start_time": "2024-04-22T20:28:04.154147800Z"
    }
   },
   "id": "2b5ca6c397a5a015",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calibrated Stream"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f7c7af8e0a71ac8"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target found\n"
     ]
    }
   ],
   "source": [
    "# Start the capture\n",
    "pipe.start(cfg)\n",
    "\n",
    "while True:\n",
    "    # Wait for a coherent pair of frames \"depth and color\" and align \n",
    "    # them\n",
    "    frame = pipe.wait_for_frames()\n",
    "    aligned_frame = align.process(frame)\n",
    "\n",
    "    # Retrieve the color flow\n",
    "    color_frame = frame.get_color_frame()\n",
    "    \n",
    "    if not color_frame:\n",
    "        continue\n",
    "\n",
    "    # Show the RGB frame\n",
    "    color_image = np.asanyarray(color_frame.get_data())\n",
    "    cv2.imshow('Color Image', color_image)\n",
    "\n",
    "    # Find the target corner in the frame\n",
    "    found, corners = cv2.findChessboardCorners(color_image, \n",
    "        pattern_size, flags=cv2.CALIB_CB_ADAPTIVE_THRESH + \n",
    "        cv2.CALIB_CB_FAST_CHECK +\n",
    "        cv2.CALIB_CB_NORMALIZE_IMAGE)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'): break\n",
    "\n",
    "    if found:\n",
    "        print(\"Target found\")\n",
    "        # Draw the shape of the target\n",
    "        images.append(objp)\n",
    "        cv2.drawChessboardCorners(color_image, pattern_size, \n",
    "            corners, found)\n",
    "        \n",
    "        # Change RBG for Grayscale\n",
    "        gray_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Apply cornerSubPix on the gray picture\n",
    "        corners_refined = cv2.cornerSubPix(gray_image, corners, \n",
    "            winSize, zeroZone, criteria)\n",
    "\n",
    "        # Add the corner in the list\n",
    "        images_corners.append(corners_refined)\n",
    "\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "retval, cameraMatrix, distCoeffs, rvecs, tvecs = cv2.calibrateCamera(images, images_corners, gray_image.shape[::-1],None,None)\n",
    "\n",
    "# Real size of the target (cm)\n",
    "mire_size_cm = 23.3\n",
    "\n",
    "# Focal in pixels accros the x-axis\n",
    "fx = cameraMatrix[0, 0]  \n",
    "taille_pixel_x = 1 / fx\n",
    "# Focal in pixels accros the y-axis\n",
    "fy = cameraMatrix[1, 1]  \n",
    "taille_pixel_y = 1 / fy\n",
    "\n",
    "decimation = rs.decimation_filter()\n",
    "decimation.set_option(rs.option.filter_magnitude, 1)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "  # Start the capture\n",
    "  #pipe.start(cfg)\n",
    "\n",
    "  while True:\n",
    "    # Wait for a coherent pair of frames \"depth and color\" and align them\n",
    "    frame = pipe.wait_for_frames()\n",
    "    aligned_frame = align.process(frame)\n",
    "\n",
    "    # Retrieve the depth and color flow\n",
    "    depth_frame = frame.get_depth_frame()\n",
    "    color_frame = frame.get_color_frame()\n",
    "\n",
    "    # Apply smothering filter\n",
    "    spatial = rs.spatial_filter()\n",
    "    spatial.set_option(rs.option.filter_magnitude, 5)\n",
    "    spatial.set_option(rs.option.filter_smooth_alpha, 1)\n",
    "    spatial.set_option(rs.option.filter_smooth_delta, 50)\n",
    "\n",
    "    # Apply filters to fill the holes\n",
    "    hole_filling = rs.hole_filling_filter()\n",
    "\n",
    "    # Retrieve the images from both flow (colorized depth)\n",
    "    colorizer = rs.colorizer()\n",
    "    color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "    decimated_depth = decimation.process(depth_frame)\n",
    "    smoothed_depth = spatial.process(decimated_depth)\n",
    "    filled_depth = hole_filling.process(smoothed_depth)\n",
    "    depth_image = np.asanyarray(filled_depth.get_data())\n",
    "    colorized_depth_frame = np.asanyarray(colorizer.colorize(filled_depth).get_data())\n",
    "\n",
    "    # Add MP on the colored image\n",
    "    color_image_rgb = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)\n",
    "    color_image_rgb.flags.writeable = False\n",
    "\n",
    "    results = pose.process(color_image_rgb)\n",
    "\n",
    "    color_image_rgb.flags.writeable = True\n",
    "    color_image_rgb = cv2.cvtColor(color_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Render detections\n",
    "    mp_drawing.draw_landmarks(color_image_rgb, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),\n",
    "                              mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                               )\n",
    "\n",
    "    # Retrieve and print the coordinates for each landmark\n",
    "    if results.pose_landmarks:\n",
    "        for landmark in results.pose_landmarks.landmark:\n",
    "            x = int(landmark.x * color_image.shape[1])\n",
    "            y = int(landmark.y * color_image.shape[0]) \n",
    "            # Print the calculated coordinates\n",
    "            print(f\"X = {x*taille_pixel_x}, Y = {y*taille_pixel_y}\")\n",
    "            \n",
    "            # Ensure that the calculated pixel coordinates are within the bounds of the depth frame\n",
    "            if 0 <= y < color_image.shape[0] and 0 <= x < color_image.shape[1]:\n",
    "                depth_value = depth_frame.get_distance(x,y)\n",
    "                print(f\"Z = {depth_value}\")\n",
    "            else:\n",
    "                print(\"Coordinates out of bounds\")\n",
    "            text = f\"X={x*taille_pixel_x:.2f}, Y={y*taille_pixel_y:.2f}, Z={depth_value:.2f}\"\n",
    "            cv2.putText(color_image_rgb, text, (x + 10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    cv2.imshow(\"Depth\", colorized_depth_frame)\n",
    "    cv2.imshow(\"Color\", color_image)\n",
    "    cv2.imshow(\"MediaPipe\", color_image_rgb)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "      break\n",
    "\n",
    "  pipe.stop()\n",
    "  cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-04-22T20:49:15.553606300Z"
    }
   },
   "id": "322b4fc1fe458977",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
